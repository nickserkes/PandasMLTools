{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. pd.read_csv()\n",
    "import pandas as pd\n",
    "\n",
    "# Parameters:\n",
    "# filepath_or_buffer (str): Path or URL of the CSV file.\n",
    "# sep (str, optional): Field delimiter. Default is ','.\n",
    "# header (int or list of int, optional): Row number(s) to use as column names.\n",
    "# index_col (int, str, sequence of int / str, or False, optional): Column(s) to set as index.\n",
    "\n",
    "# Load a CSV file into a DataFrame\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "# Display the first few rows\n",
    "print(df.head())\n",
    "# Output: DataFrame showing first 5 rows of the CSV data with column headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. pd.DataFrame()\n",
    "# Parameters:\n",
    "# data (array-like, dict, or DataFrame): The data to be stored in the DataFrame.\n",
    "# index (array-like, optional): The index (row labels).\n",
    "# columns (array-like, optional): Column labels.\n",
    "\n",
    "# Create a DataFrame from a dictionary\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "    'Age': [24, 27, 22],\n",
    "    'City': ['New York', 'Los Angeles', 'Chicago']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n",
    "# Output: DataFrame with 3 rows containing Name, Age, and City data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. .head()\n",
    "# Parameters:\n",
    "# n (int): Number of rows to display from the top. Default is 5.\n",
    "\n",
    "# Display the first few rows of a DataFrame\n",
    "print(df.head(3))  # Shows the first 3 rows\n",
    "# Output: First 3 rows of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. .tail()\n",
    "# Parameters:\n",
    "# n (int): Number of rows to display from the bottom. Default is 5.\n",
    "\n",
    "# Display the last few rows of a DataFrame\n",
    "print(df.tail(2))  # Shows the last 2 rows\n",
    "# Output: Last 2 rows of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. .info()\n",
    "# Parameters: None\n",
    "\n",
    "# Provides a concise summary of the DataFrame\n",
    "df.info()\n",
    "# Output: DataFrame information including index, column names, non-null counts, and memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. .describe()\n",
    "# Parameters:\n",
    "# percentiles (list-like of numbers, optional): Percentiles to include in the output.\n",
    "# include (str or list-like, optional): Specify data types to include (e.g., 'all').\n",
    "# exclude (str or list-like, optional): Specify data types to exclude.\n",
    "\n",
    "# Provides summary statistics for numerical columns\n",
    "print(df.describe())\n",
    "# Output: Statistical summary of numerical columns (count, mean, std, min, 25%, 50%, 75%, max)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. .shape\n",
    "# Parameters: None\n",
    "\n",
    "# Returns the dimensions of the DataFrame (rows, columns)\n",
    "print(df.shape)  # Output example: (3, 3) means 3 rows, 3 columns\n",
    "# Output: Tuple showing dimensions (e.g., (3, 3) for 3 rows and 3 columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. .columns\n",
    "# Parameters: None\n",
    "\n",
    "# Returns the column names of the DataFrame\n",
    "print(df.columns)\n",
    "# Output: Index object containing column names (e.g., Index(['Name', 'Age', 'City'], dtype='object'))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. .dtypes\n",
    "# Parameters: None\n",
    "\n",
    "# Returns the data types of each column in the DataFrame\n",
    "print(df.dtypes)\n",
    "# Output: Series showing data type of each column (e.g., Name: object, Age: int64, City: object)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. .isnull()\n",
    "# Parameters: None\n",
    "\n",
    "# Checks for missing values and returns a DataFrame of booleans\n",
    "print(df.isnull())\n",
    "# Output: DataFrame of same shape with boolean values (True for null, False for non-null)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. .fillna()\n",
    "# Parameters:\n",
    "# value (scalar, dict, Series, or DataFrame): Value to replace NaNs with.\n",
    "# method (str, optional): Method to use for filling holes ('backfill', 'bfill', 'pad', 'ffill').\n",
    "# axis (int or str, optional): Axis along which to fill (0 for rows, 1 for columns).\n",
    "# inplace (bool, optional): Modify the DataFrame in place (default is False).\n",
    "\n",
    "# Fill missing values with a specified value\n",
    "df_filled = df.fillna(0)\n",
    "print(df_filled)\n",
    "# Output: DataFrame with missing values replaced by specified value (0 in this case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. .dropna()\n",
    "# Parameters:\n",
    "# axis (int or str, optional): Axis along which to drop rows or columns (0 for rows, 1 for columns).\n",
    "# how (str, optional): 'any' (default) drops if any NaN values; 'all' drops if all values are NaN.\n",
    "# inplace (bool, optional): Modify the DataFrame in place (default is False).\n",
    "# subset (array-like, optional): Labels of columns to consider for dropping NA.\n",
    "\n",
    "# Drop rows with missing values\n",
    "df_dropped = df.dropna()\n",
    "print(df_dropped)\n",
    "# Output: DataFrame with rows containing null values removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. .groupby()\n",
    "# Parameters:\n",
    "# by (str or list of str): Column(s) to group by.\n",
    "# axis (int or str, optional): Axis along which to group.\n",
    "# as_index (bool, optional): If True, the group labels become index; otherwise, group labels are columns.\n",
    "\n",
    "# Group by a column and calculate the mean for each group\n",
    "grouped = df.groupby('City').mean()\n",
    "print(grouped)\n",
    "# Output: DataFrame showing mean values for each unique city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14. .apply()\n",
    "# Parameters:\n",
    "# func (function): The function to apply to each element.\n",
    "# axis (int, optional): 0 for applying function to each column, 1 for each row.\n",
    "# result_type (str, optional): 'expand', 'reduce', 'broadcast' (default is None).\n",
    "\n",
    "# Apply a function to each column\n",
    "df['Age_plus_10'] = df['Age'].apply(lambda x: x + 10)\n",
    "print(df)\n",
    "# Output: DataFrame with new 'Age_plus_10' column containing Age values increased by 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15. .loc[]\n",
    "# Parameters:\n",
    "# row_label(s): Row label(s) to select.\n",
    "# column_label(s): Column label(s) to select.\n",
    "# Supports slicing and Boolean indexing.\n",
    "\n",
    "# Select specific rows and columns by labels\n",
    "print(df.loc[0:1, ['Name', 'City']])  # Selects the first two rows and specific columns\n",
    "# Output: DataFrame subset with first two rows and Name/City columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16. .iloc[]\n",
    "# Parameters:\n",
    "# row_position(s): Row index/position(s) to select.\n",
    "# column_position(s): Column index/position(s) to select.\n",
    "# Supports integer-based slicing.\n",
    "\n",
    "# Select specific rows and columns by position\n",
    "print(df.iloc[0:2, 0:2])  # Selects the first two rows and the first two columns\n",
    "# Output: DataFrame subset with first two rows and first two columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17. .merge()\n",
    "# Parameters:\n",
    "# right (DataFrame): The DataFrame to merge with.\n",
    "# how (str, optional): Type of merge ('left', 'right', 'outer', 'inner'). Default is 'inner'.\n",
    "# on (label or list, optional): Column(s) to join on. If None, uses common columns.\n",
    "# left_on/right_on (label or list, optional): Columns to join on from the left and right DataFrames.\n",
    "\n",
    "# Merge two DataFrames on a common column\n",
    "df1 = pd.DataFrame({'ID': [1, 2, 3], 'Name': ['Alice', 'Bob', 'Charlie']})\n",
    "df2 = pd.DataFrame({'ID': [1, 2, 3], 'Age': [24, 27, 22]})\n",
    "merged_df = pd.merge(df1, df2, on='ID')\n",
    "print(merged_df)\n",
    "# Output: DataFrame combining df1 and df2 based on 'ID' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 18. .concat()\n",
    "# Parameters:\n",
    "# objs (list of DataFrames): List of DataFrames to concatenate.\n",
    "# axis (int, optional): Axis along which to concatenate (0 for rows, 1 for columns). Default is 0.\n",
    "# join (str, optional): 'inner' for intersection or 'outer' for union. Default is 'outer'.\n",
    "\n",
    "# Concatenate two DataFrames along rows\n",
    "df1 = pd.DataFrame({'Name': ['Alice', 'Bob']})\n",
    "df2 = pd.DataFrame({'Name': ['Charlie', 'David']})\n",
    "concat_df = pd.concat([df1, df2], axis=0)\n",
    "print(concat_df)\n",
    "# Output: DataFrame combining df1 and df2 vertically with reset index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 19. .sort_values()\n",
    "# Parameters:\n",
    "# by (str or list of str): Column(s) to sort by.\n",
    "# axis (int, optional): Axis along which to sort (0 for rows, 1 for columns). Default is 0.\n",
    "# ascending (bool or list of bool, optional): Sort in ascending order or not. Default is True.\n",
    "# inplace (bool, optional): Modify the DataFrame in place. Default is False.\n",
    "\n",
    "# Sort DataFrame by a column\n",
    "sorted_df = df.sort_values(by='Age', ascending=False)\n",
    "print(sorted_df)\n",
    "# Output: DataFrame sorted by Age column in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20. .pivot_table()\n",
    "# Parameters:\n",
    "# values (str or list, optional): Column(s) to aggregate.\n",
    "# index (str or list): Column(s) to group by as the new index.\n",
    "# columns (str or list, optional): Column(s) to pivot into new columns.\n",
    "# aggfunc (function or list, default 'mean'): Aggregation function to apply.\n",
    "\n",
    "# Create a pivot table\n",
    "pivot_df = df.pivot_table(values='Age', index='City', aggfunc='mean')\n",
    "print(pivot_df)\n",
    "# Output: DataFrame showing mean Age values for each unique City."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 21. .rename()\n",
    "# Parameters:\n",
    "# mapper (dict or function): Dictionary or function to rename columns/index.\n",
    "# axis (int or str, optional): Specifies whether to rename columns (1 or 'columns') or index (0 or 'index').\n",
    "# inplace (bool, optional): Whether to modify the DataFrame in place. Default is False.\n",
    "\n",
    "# Rename columns in the DataFrame\n",
    "df_renamed = df.rename(columns={'Name': 'Full Name', 'Age': 'Years'})\n",
    "print(df_renamed)\n",
    "# Output: DataFrame with renamed columns ('Name' to 'Full Name', 'Age' to 'Years')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 22. .value_counts()\n",
    "# Parameters:\n",
    "# normalize (bool, optional): If True, returns the relative frequencies.\n",
    "# sort (bool, optional): If True, sorts values in descending order. Default is True.\n",
    "# ascending (bool, optional): If True, sorts in ascending order.\n",
    "\n",
    "# Count occurrences of each unique value in a column\n",
    "counts = df['City'].value_counts()\n",
    "print(counts)\n",
    "# Output: Series showing frequency of each unique City value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 23. .sample()\n",
    "# Parameters:\n",
    "# n (int, optional): Number of items to sample.\n",
    "# frac (float, optional): Fraction of items to sample.\n",
    "# replace (bool, optional): Whether to sample with replacement.\n",
    "# random_state (int, optional): Seed for the random number generator.\n",
    "\n",
    "# Sample 2 random rows from the DataFrame\n",
    "sampled_df = df.sample(n=2)\n",
    "print(sampled_df)\n",
    "# Output: DataFrame containing 2 randomly selected rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 24. .astype()\n",
    "# Parameters:\n",
    "# dtype (str, dtype, or dict): The type to cast each column to.\n",
    "# errors (str, optional): 'raise' to raise an error if casting fails; 'ignore' to do nothing.\n",
    "\n",
    "# Convert a column to a different data type\n",
    "df['Age'] = df['Age'].astype(float)\n",
    "print(df.dtypes)\n",
    "# Output: Series showing updated data types with Age column as float64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 25. .drop()\n",
    "# Parameters:\n",
    "# labels (str or list): Index or column labels to drop.\n",
    "# axis (int or str, optional): Axis along which to drop labels (0 for rows, 1 for columns).\n",
    "# inplace (bool, optional): Whether to modify the DataFrame in place. Default is False.\n",
    "\n",
    "# Drop a column from the DataFrame\n",
    "df_dropped = df.drop(columns=['City'])\n",
    "print(df_dropped)\n",
    "# Output: DataFrame with City column removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 26. .duplicated()\n",
    "# Parameters:\n",
    "# subset (str or list-like, optional): Columns to check for duplicates.\n",
    "# keep (str, optional): 'first', 'last', or False to mark duplicates.\n",
    "# Returns a boolean Series indicating duplicated rows.\n",
    "\n",
    "# Check for duplicate rows based on a column\n",
    "duplicates = df.duplicated(subset=['Name'])\n",
    "print(duplicates)\n",
    "# Output: Boolean Series indicating which rows have duplicate Name values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 27. .corr()\n",
    "# Parameters:\n",
    "# method (str, optional): Correlation method ('pearson', 'kendall', 'spearman').\n",
    "# min_periods (int, optional): Minimum number of observations required.\n",
    "\n",
    "# Calculate the correlation matrix for numerical columns\n",
    "correlation_matrix = df.corr()\n",
    "print(correlation_matrix)\n",
    "# Output: DataFrame showing correlation coefficients between numerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 28. .reset_index()\n",
    "# Parameters:\n",
    "# drop (bool, optional): If True, does not add the index as a column.\n",
    "# inplace (bool, optional): Modify the DataFrame in place. Default is False.\n",
    "\n",
    "# Reset the index of the DataFrame\n",
    "df_reset = df.reset_index(drop=True)\n",
    "print(df_reset)\n",
    "# Output: DataFrame with reset sequential integer index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 29. .nlargest()\n",
    "# Parameters:\n",
    "# n (int): Number of top items to select.\n",
    "# columns (str or list): Column(s) to use for sorting.\n",
    "\n",
    "# Select the top 2 rows with the highest values in the 'Age' column\n",
    "top_ages = df.nlargest(2, 'Age')\n",
    "print(top_ages)\n",
    "# Output: DataFrame with 2 rows having the highest Age values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30. .nsmallest()\n",
    "# Parameters:\n",
    "# n (int): Number of smallest items to select.\n",
    "# columns (str or list): Column(s) to use for sorting.\n",
    "\n",
    "# Select the top 2 rows with the smallest values in the 'Age' column\n",
    "smallest_ages = df.nsmallest(2, 'Age')\n",
    "print(smallest_ages)\n",
    "# Output: DataFrame with 2 rows having the lowest Age values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 31. .set_index()\n",
    "# Parameters:\n",
    "# keys (str or array-like): Column(s) to set as index.\n",
    "# drop (bool, optional): Whether to drop the column(s) from the DataFrame. Default is True.\n",
    "# inplace (bool, optional): Modify the DataFrame in place. Default is False.\n",
    "\n",
    "# Set 'Name' column as the index\n",
    "df_indexed = df.set_index('Name')\n",
    "print(df_indexed)\n",
    "# Output: DataFrame with 'Name' column as the new index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 32. .sort_index()\n",
    "# Parameters:\n",
    "# axis (int, optional): Axis to sort (0 for rows, 1 for columns).\n",
    "# ascending (bool, optional): Sort ascending or descending. Default is True.\n",
    "# inplace (bool, optional): Modify the DataFrame in place. Default is False.\n",
    "\n",
    "# Sort DataFrame by index\n",
    "sorted_by_index = df_indexed.sort_index()\n",
    "print(sorted_by_index)\n",
    "# Output: DataFrame sorted by the index (e.g., alphabetical order of 'Name' if set as index)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 33. .cumsum()\n",
    "# Parameters:\n",
    "# axis (int, optional): Axis along which to calculate cumulative sum (0 for index, 1 for columns).\n",
    "# skipna (bool, optional): Exclude NA/null values. Default is True.\n",
    "\n",
    "# Calculate cumulative sum for each numeric column\n",
    "cumsum_df = df[['Age']].cumsum()\n",
    "print(cumsum_df)\n",
    "# Output: DataFrame with cumulative sum of values in 'Age' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 34. .cumprod()\n",
    "# Parameters:\n",
    "# axis (int, optional): Axis along which to calculate cumulative product (0 for index, 1 for columns).\n",
    "# skipna (bool, optional): Exclude NA/null values. Default is True.\n",
    "\n",
    "# Calculate cumulative product for each numeric column\n",
    "cumprod_df = df[['Age']].cumprod()\n",
    "print(cumprod_df)\n",
    "# Output: DataFrame with cumulative product of values in 'Age' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 35. .diff()\n",
    "# Parameters:\n",
    "# periods (int, optional): Number of periods to calculate difference. Default is 1.\n",
    "# axis (int, optional): Axis along which to calculate difference. Default is 0.\n",
    "\n",
    "# Calculate the difference between consecutive values in the 'Age' column\n",
    "diff_df = df[['Age']].diff()\n",
    "print(diff_df)\n",
    "# Output: DataFrame showing the difference between each row and the previous row in 'Age' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 36. .rank()\n",
    "# Parameters:\n",
    "# axis (int, optional): Axis to rank along. Default is 0.\n",
    "# method (str, optional): Ranking method ('average', 'min', 'max', 'first', 'dense'). Default is 'average'.\n",
    "# ascending (bool, optional): Rank in ascending order. Default is True.\n",
    "\n",
    "# Rank values in the 'Age' column\n",
    "rank_df = df[['Age']].rank()\n",
    "print(rank_df)\n",
    "# Output: DataFrame with rank of each value in 'Age' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 37. .explode()\n",
    "# Parameters:\n",
    "# column (str): Column to explode.\n",
    "# ignore_index (bool, optional): If True, reset index after exploding. Default is False.\n",
    "\n",
    "# Example with a DataFrame containing a list in one column\n",
    "df_explode = pd.DataFrame({'Name': ['Alice', 'Bob'], 'Hobbies': [['Reading', 'Cooking'], ['Sports']]})\n",
    "exploded_df = df_explode.explode('Hobbies')\n",
    "print(exploded_df)\n",
    "# Output: DataFrame with one row per element in the 'Hobbies' list, duplicating 'Name' values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 38. .transpose()\n",
    "# Parameters: None\n",
    "\n",
    "# Transpose the DataFrame (swap rows and columns)\n",
    "transposed_df = df.transpose()\n",
    "print(transposed_df)\n",
    "# Output: DataFrame with rows and columns swapped (rows become columns and vice versa)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 39. .memory_usage()\n",
    "# Parameters:\n",
    "# index (bool, optional): If True, include memory usage of the DataFrame's index. Default is True.\n",
    "# deep (bool, optional): If True, analyze deep memory usage of object dtype columns.\n",
    "\n",
    "# Check memory usage of each column\n",
    "memory_usage = df.memory_usage(deep=True)\n",
    "print(memory_usage)\n",
    "# Output: Series showing memory usage of each column in bytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 40. .query()\n",
    "# Parameters:\n",
    "# expr (str): The query string (boolean expression to filter rows).\n",
    "# inplace (bool, optional): Modify the DataFrame in place. Default is False.\n",
    "\n",
    "# Filter rows based on a condition\n",
    "query_df = df.query('Age > 25')\n",
    "print(query_df)\n",
    "# Output: DataFrame with rows where 'Age' is greater than 25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 41. .pivot()\n",
    "# Parameters:\n",
    "# index (str or list): Column(s) to use as row labels.\n",
    "# columns (str or list): Column(s) to use as new columns.\n",
    "# values (str, optional): Column to use for populating values.\n",
    "\n",
    "# Pivot data to restructure the DataFrame\n",
    "pivoted_df = df.pivot(index='Name', columns='City', values='Age')\n",
    "print(pivoted_df)\n",
    "# Output: DataFrame where 'Name' is the index, unique 'City' values are columns, and 'Age' values fill the cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 42. .melt()\n",
    "# Parameters:\n",
    "# id_vars (str or list): Column(s) to keep as identifier variables.\n",
    "# value_vars (str or list, optional): Column(s) to unpivot.\n",
    "# var_name (str, optional): Name for the variable column.\n",
    "# value_name (str, optional): Name for the value column.\n",
    "\n",
    "# Unpivot the DataFrame from wide to long format\n",
    "melted_df = df.melt(id_vars=['Name'], value_vars=['Age', 'City'], var_name='Attribute', value_name='Value')\n",
    "print(melted_df)\n",
    "# Output: DataFrame in long format with 'Name' as identifier and 'Age'/'City' values in 'Attribute' and 'Value' columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 43. .isin()\n",
    "# Parameters:\n",
    "# values (list, Series, dict, or DataFrame): Values to check for presence.\n",
    "\n",
    "# Filter rows based on whether values are in a specified list\n",
    "filtered_df = df[df['City'].isin(['New York', 'Chicago'])]\n",
    "print(filtered_df)\n",
    "# Output: DataFrame with rows where 'City' is either 'New York' or 'Chicago'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 44. .nunique()\n",
    "# Parameters:\n",
    "# axis (int, optional): Axis along which to count unique values (0 for rows, 1 for columns).\n",
    "# dropna (bool, optional): Whether to include NaN in the count. Default is True.\n",
    "\n",
    "# Get the number of unique values in each column\n",
    "unique_counts = df.nunique()\n",
    "print(unique_counts)\n",
    "# Output: Series showing the count of unique values in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 45. .select_dtypes()\n",
    "# Parameters:\n",
    "# include (str, list-like, or None): Data types to include.\n",
    "# exclude (str, list-like, or None): Data types to exclude.\n",
    "\n",
    "# Select columns with a specific data type (e.g., numeric)\n",
    "numeric_df = df.select_dtypes(include='number')\n",
    "print(numeric_df)\n",
    "# Output: DataFrame with only numeric columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 46. .agg()\n",
    "# Parameters:\n",
    "# func (function, str, list, or dict): Aggregation function(s) to apply.\n",
    "# axis (int, optional): Axis along which to aggregate. Default is 0.\n",
    "\n",
    "# Perform multiple aggregations on a column\n",
    "agg_df = df[['Age']].agg(['mean', 'min', 'max'])\n",
    "print(agg_df)\n",
    "# Output: DataFrame with 'mean', 'min', and 'max' of 'Age' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 47. .applymap()\n",
    "# Parameters:\n",
    "# func (function): Function to apply to each element of the DataFrame.\n",
    "\n",
    "# Apply a function to each element of the DataFrame\n",
    "formatted_df = df[['Age']].applymap(lambda x: f\"{x} years\")\n",
    "print(formatted_df)\n",
    "# Output: DataFrame where each value in 'Age' column is formatted as a string (e.g., \"24 years\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 48. .idxmax()\n",
    "# Parameters:\n",
    "# axis (int, optional): Axis along which to find the index. Default is 0.\n",
    "# skipna (bool, optional): Exclude NA/null values. Default is True.\n",
    "\n",
    "# Get the index of the maximum value in each column\n",
    "max_index = df['Age'].idxmax()\n",
    "print(max_index)\n",
    "# Output: Index of the row with the highest value in 'Age' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 49. .idxmin()\n",
    "# Parameters:\n",
    "# axis (int, optional): Axis along which to find the index. Default is 0.\n",
    "# skipna (bool, optional): Exclude NA/null values. Default is True.\n",
    "\n",
    "# Get the index of the minimum value in each column\n",
    "min_index = df['Age'].idxmin()\n",
    "print(min_index)\n",
    "# Output: Index of the row with the lowest value in 'Age' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 50. .where()\n",
    "# Parameters:\n",
    "# cond (boolean Series/DataFrame): Condition to evaluate.\n",
    "# other (scalar, Series, or DataFrame, optional): Value(s) to use where the condition is False.\n",
    "# inplace (bool, optional): Modify the DataFrame in place. Default is False.\n",
    "\n",
    "# Replace values in 'Age' column with NaN where 'Age' is less than 25\n",
    "filtered_age_df = df['Age'].where(df['Age'] >= 25)\n",
    "print(filtered_age_df)\n",
    "# Output: Series with 'Age' values under 25 replaced with NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 51. .applymap()\n",
    "# Parameters:\n",
    "# func (function): A function to apply to each element of the DataFrame.\n",
    "\n",
    "# Apply a function to each element of the DataFrame (e.g., format each value as a string)\n",
    "formatted_df = df.applymap(lambda x: f\"{x} units\" if isinstance(x, (int, float)) else x)\n",
    "print(formatted_df)\n",
    "# Output: DataFrame with each numeric element formatted as a string (e.g., \"24 units\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 52. .at[]\n",
    "# Parameters:\n",
    "# label (scalar): Row label.\n",
    "# column (scalar): Column label.\n",
    "\n",
    "# Access a specific element by row and column labels\n",
    "value = df.at[0, 'Age']\n",
    "print(value)\n",
    "# Output: The value in the first row of the 'Age' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 53. .iat[]\n",
    "# Parameters:\n",
    "# row_position (int): Row index.\n",
    "# column_position (int): Column index.\n",
    "\n",
    "# Access a specific element by integer position\n",
    "value = df.iat[0, 1]  # First row, second column\n",
    "print(value)\n",
    "# Output: The value at the specified row and column position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 54. .any()\n",
    "# Parameters:\n",
    "# axis (int, optional): Axis to check for True values. Default is 0.\n",
    "# skipna (bool, optional): Exclude NA/null values. Default is True.\n",
    "\n",
    "# Check if any value in each column is True (non-zero)\n",
    "any_true = df.any()\n",
    "print(any_true)\n",
    "# Output: Series showing True if any value in each column is True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 55. .all()\n",
    "# Parameters:\n",
    "# axis (int, optional): Axis to check if all values are True. Default is 0.\n",
    "# skipna (bool, optional): Exclude NA/null values. Default is True.\n",
    "\n",
    "# Check if all values in each column are True (non-zero)\n",
    "all_true = df.all()\n",
    "print(all_true)\n",
    "# Output: Series showing True if all values in each column are True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 56. .combine_first()\n",
    "# Parameters:\n",
    "# other (DataFrame): The other DataFrame to combine with.\n",
    "\n",
    "# Fill missing values in a DataFrame with values from another DataFrame\n",
    "df1 = pd.DataFrame({'A': [1, None, 3], 'B': [4, 5, None]})\n",
    "df2 = pd.DataFrame({'A': [7, 8, 9], 'B': [10, 11, 12]})\n",
    "combined_df = df1.combine_first(df2)\n",
    "print(combined_df)\n",
    "# Output: DataFrame with missing values in `df1` filled by values from `df2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 57. .duplicated()\n",
    "# Parameters:\n",
    "# subset (str or list-like, optional): Columns to check for duplicates.\n",
    "# keep (str, optional): 'first', 'last', or False to mark duplicates.\n",
    "\n",
    "# Check for duplicated rows\n",
    "duplicates = df.duplicated(subset='Name', keep=False)\n",
    "print(duplicates)\n",
    "# Output: Series indicating True for duplicated rows based on the 'Name' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 58. .equals()\n",
    "# Parameters:\n",
    "# other (DataFrame): The other DataFrame to compare.\n",
    "\n",
    "# Check if two DataFrames are equal\n",
    "df1 = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})\n",
    "df2 = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})\n",
    "are_equal = df1.equals(df2)\n",
    "print(are_equal)\n",
    "# Output: True if `df1` and `df2` are exactly the same; otherwise, False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 59. .set_axis()\n",
    "# Parameters:\n",
    "# labels (array-like): The new labels to set.\n",
    "# axis (int, optional): The axis to set labels for (0 for rows, 1 for columns).\n",
    "# inplace (bool, optional): Modify the DataFrame in place. Default is False.\n",
    "\n",
    "# Set new column names\n",
    "df_set_axis = df.set_axis(['Col1', 'Col2', 'Col3'], axis=1, inplace=False)\n",
    "print(df_set_axis)\n",
    "# Output: DataFrame with updated column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 60. .squeeze()\n",
    "# Parameters:\n",
    "# axis (None or int, optional): Squeeze along specified axis if possible.\n",
    "\n",
    "# Convert a single-column or single-row DataFrame to a Series\n",
    "single_col_df = pd.DataFrame({'A': [1, 2, 3]})\n",
    "squeezed_series = single_col_df.squeeze()\n",
    "print(squeezed_series)\n",
    "# Output: Series if the DataFrame has only one column or row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 61. .copy()\n",
    "# Parameters:\n",
    "# deep (bool, optional): Whether to copy underlying data. Default is False.\n",
    "\n",
    "# Create a copy of the DataFrame\n",
    "df_copy = df.copy(deep=True)\n",
    "print(df_copy)\n",
    "# Output: A deep copy of the original DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Forward Filling (`.fillna(method='ffill')`)\n",
    "# Parameters:\n",
    "# method (str, optional): Specifies the fill method ('ffill' for forward fill, 'bfill' for backward fill).\n",
    "# axis (int, optional): Axis along which to fill (0 for index/rows, 1 for columns). Default is 0.\n",
    "# inplace (bool, optional): If True, modifies the DataFrame in place. Default is False.\n",
    "\n",
    "# Sample DataFrame with missing values\n",
    "df = pd.DataFrame({'A': [1, None, None, 4, 5]})\n",
    "\n",
    "# Forward fill missing values\n",
    "df_ffill = df.fillna(method='ffill')\n",
    "print(df_ffill)\n",
    "# Output: DataFrame with missing values filled using the last known value.\n",
    "#     A\n",
    "# 0  1.0\n",
    "# 1  1.0\n",
    "# 2  1.0\n",
    "# 3  4.0\n",
    "# 4  5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Backward Filling (`.fillna(method='bfill')`)\n",
    "# Parameters:\n",
    "# method (str, optional): Specifies the fill method ('ffill' for forward fill, 'bfill' for backward fill).\n",
    "# axis (int, optional): Axis along which to fill (0 for index/rows, 1 for columns). Default is 0.\n",
    "# inplace (bool, optional): If True, modifies the DataFrame in place. Default is False.\n",
    "\n",
    "# Backward fill missing values\n",
    "df_bfill = df.fillna(method='bfill')\n",
    "print(df_bfill)\n",
    "# Output: DataFrame with missing values filled using the next known value.\n",
    "#     A\n",
    "# 0  1.0\n",
    "# 1  4.0\n",
    "# 2  4.0\n",
    "# 3  4.0\n",
    "# 4  5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Clipping Values (`.clip()`)\n",
    "# Parameters:\n",
    "# lower (float or int, optional): Minimum threshold value. All values below this will be set to `lower`.\n",
    "# upper (float or int, optional): Maximum threshold value. All values above this will be set to `upper`.\n",
    "# axis (int, optional): Axis along which to clip values. Default is None (applies to all values).\n",
    "\n",
    "# Clip values in column 'A' to be within the range [2, 4]\n",
    "df_clipped = df.clip(lower=2, upper=4)\n",
    "print(df_clipped)\n",
    "# Output: DataFrame with values clipped to the specified range.\n",
    "#     A\n",
    "# 0  2.0\n",
    "# 1  NaN\n",
    "# 2  NaN\n",
    "# 3  4.0\n",
    "# 4  4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Winsorizing (Using `scipy.stats.mstats.winsorize`)\n",
    "# Parameters:\n",
    "# limits (tuple of floats): Limits on both sides, as a proportion (e.g., (0.05, 0.05) limits the bottom 5% and top 5%).\n",
    "# inclusive (tuple of bools, optional): Whether to include values exactly equal to the limits. Default is (True, True).\n",
    "\n",
    "from scipy.stats.mstats import winsorize\n",
    "\n",
    "# Winsorize values in column 'A' to limit extreme values\n",
    "df['A'] = winsorize(df['A'], limits=[0.05, 0.05])\n",
    "print(df)\n",
    "# Output: DataFrame with extreme values at the tails limited to the specified percentiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Converting a String Date into a Datetime Object (`pd.to_datetime()`)\n",
    "# Parameters:\n",
    "# arg (str, list-like, Series, or DataFrame): Dates to convert.\n",
    "# format (str, optional): Specify the date format (e.g., '%Y-%m-%d') if known to improve speed.\n",
    "# errors (str, optional): 'raise' to raise an error, 'coerce' to set invalid parsing as NaT, 'ignore' to skip parsing errors.\n",
    "\n",
    "# Sample DataFrame with string dates\n",
    "df_dates = pd.DataFrame({'Date': ['2023-01-01', '2023-02-15', '2023-03-20']})\n",
    "\n",
    "# Convert to datetime format\n",
    "df_dates['Date'] = pd.to_datetime(df_dates['Date'])\n",
    "print(df_dates)\n",
    "# Output: DataFrame with 'Date' column converted to datetime objects.\n",
    "#         Date\n",
    "# 0 2023-01-01\n",
    "# 1 2023-02-15\n",
    "# 2 2023-03-20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Changing a Column to Become the Index (`.set_index()`)\n",
    "# Parameters:\n",
    "# keys (str or list): Column(s) to set as the index.\n",
    "# drop (bool, optional): Whether to drop the column(s) from the DataFrame. Default is True.\n",
    "# inplace (bool, optional): If True, modifies the DataFrame in place. Default is False.\n",
    "\n",
    "# Set 'Date' column as the index\n",
    "df_dates_indexed = df_dates.set_index('Date')\n",
    "print(df_dates_indexed)\n",
    "# Output: DataFrame with 'Date' as the index.\n",
    "# Empty DataFrame\n",
    "# Columns: []\n",
    "# Index: [2023-01-01, 2023-02-15, 2023-03-20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Resetting the Index to a Column (`.reset_index()`)\n",
    "# Parameters:\n",
    "# drop (bool, optional): If True, do not add the index as a column. Default is False.\n",
    "# inplace (bool, optional): If True, modifies the DataFrame in place. Default is False.\n",
    "\n",
    "# Reset the index\n",
    "df_reset = df_dates_indexed.reset_index()\n",
    "print(df_reset)\n",
    "# Output: DataFrame with the index reset and added back as a column.\n",
    "#         Date\n",
    "# 0 2023-01-01\n",
    "# 1 2023-02-15\n",
    "# 2 2023-03-20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Changing an Object Column to Integer or Float (`.astype()`)\n",
    "# Parameters:\n",
    "# dtype (str or dict): Type to cast each column to (e.g., 'int', 'float').\n",
    "# errors (str, optional): 'raise' to raise an error if casting fails, 'ignore' to skip casting errors.\n",
    "\n",
    "# Sample DataFrame with numeric data as object\n",
    "df_types = pd.DataFrame({'Value': ['10', '20', '30']})\n",
    "\n",
    "# Convert to integer\n",
    "df_types['Value'] = df_types['Value'].astype(int)\n",
    "print(df_types)\n",
    "# Output: DataFrame with 'Value' column converted to integer type.\n",
    "#    Value\n",
    "# 0     10\n",
    "# 1     20\n",
    "# 2     30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Replacing Specific Values in a DataFrame (`.replace()`)\n",
    "# Parameters:\n",
    "# to_replace (scalar, list, dict, or Series): Value(s) to replace.\n",
    "# value (scalar, list, dict, or Series): Value(s) to replace with.\n",
    "# inplace (bool, optional): If True, modifies the DataFrame in place. Default is False.\n",
    "\n",
    "# Replace specific values in a DataFrame\n",
    "df_replace = df_types.replace(10, 100)\n",
    "print(df_replace)\n",
    "# Output: DataFrame with specified values replaced.\n",
    "#    Value\n",
    "# 0    100\n",
    "# 1     20\n",
    "# 2     30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Dropping Rows with Missing Values (`.dropna()`)\n",
    "# Parameters:\n",
    "# axis (int, optional): Axis to drop from (0 for rows, 1 for columns). Default is 0.\n",
    "# how (str, optional): 'any' to drop if any NA values are present, 'all' to drop only if all values are NA. Default is 'any'.\n",
    "# subset (list, optional): Columns to consider for NA values when dropping.\n",
    "\n",
    "# Drop rows with missing values\n",
    "df_dropped = df.dropna()\n",
    "print(df_dropped)\n",
    "# Output: DataFrame with rows containing NA values dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Removing Duplicates (`.drop_duplicates()`)\n",
    "# Parameters:\n",
    "# subset (str or list, optional): Columns to consider when identifying duplicates.\n",
    "# keep (str, optional): 'first' to keep the first occurrence, 'last' to keep the last, False to drop all duplicates.\n",
    "# inplace (bool, optional): If True, modifies the DataFrame in place. Default is False.\n",
    "\n",
    "# Sample DataFrame with duplicate rows\n",
    "df_duplicates = pd.DataFrame({'A': [1, 2, 2, 3], 'B': ['x', 'y', 'y', 'z']})\n",
    "\n",
    "# Drop duplicate rows\n",
    "df_no_duplicates = df_duplicates.drop_duplicates()\n",
    "print(df_no_duplicates)\n",
    "# Output: DataFrame with duplicate rows removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. Renaming Columns (`.rename()`)\n",
    "# Parameters:\n",
    "# mapper (dict or function): Dictionary or function to rename columns/index.\n",
    "# axis (int or str, optional): Axis along which to rename (0 for rows, 1 for columns).\n",
    "# inplace (bool, optional): If True, modifies the DataFrame in place. Default is False.\n",
    "\n",
    "# Rename columns\n",
    "df_renamed = df_duplicates.rename(columns={'A': 'Alpha', 'B': 'Beta'})\n",
    "print(df_renamed)\n",
    "# Output: DataFrame with columns renamed.\n",
    "#    Alpha Beta\n",
    "# 0      1    x\n",
    "# 1      2    y\n",
    "# 2      2    y\n",
    "# 3      3    z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. Using a Lambda Function with `.apply()`\n",
    "# Parameters:\n",
    "# func (function): Function to apply to each element, row, or column.\n",
    "# axis (int, optional): Axis along which to apply the function (0 for columns, 1 for rows).\n",
    "\n",
    "# Example: Create a new column with double the value in column 'A'\n",
    "df_duplicates['A_doubled'] = df_duplicates['A'].apply(lambda x: x * 2)\n",
    "print(df_duplicates)\n",
    "# Output: DataFrame with a new column where each value in 'A' is doubled.\n",
    "#    A  B  A_doubled\n",
    "# 0  1  x          2\n",
    "# 1  2  y          4\n",
    "# 2  2  y          4\n",
    "# 3  3  z          6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14. Replacing Values with Conditions (`.where()`)\n",
    "# Parameters:\n",
    "# cond (boolean array-like): Condition to evaluate for each element.\n",
    "# other (scalar or DataFrame): Value(s) to set where the condition is False.\n",
    "# inplace (bool, optional): If True, modifies the DataFrame in place. Default is False.\n",
    "\n",
    "# Replace values in 'A' that are less than 3 with NaN\n",
    "df_where = df_duplicates['A'].where(df_duplicates['A'] >= 3, other=None)\n",
    "print(df_where)\n",
    "# Output: Series with values less than 3 replaced with NaN.\n",
    "# 0    NaN\n",
    "# 1    NaN\n",
    "# 2    NaN\n",
    "# 3    3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15. Converting Strings to Lowercase (`.str.lower()`)\n",
    "# Parameters: None (operates on a Series of string data)\n",
    "\n",
    "# Convert all strings in column 'B' to lowercase\n",
    "df_lower = df_duplicates['B'].str.lower()\n",
    "print(df_lower)\n",
    "# Output: Series with all strings in 'B' converted to lowercase.\n",
    "# 0    x\n",
    "# 1    y\n",
    "# 2    y\n",
    "# 3    z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16. Splitting a String Column (`.str.split()`)\n",
    "# Parameters:\n",
    "# pat (str, optional): String or regular expression to split on. Default is whitespace.\n",
    "# expand (bool, optional): If True, return DataFrame with each split element in a separate column.\n",
    "\n",
    "# Sample DataFrame with a column of concatenated strings\n",
    "df_split = pd.DataFrame({'Names': ['Alice-Bob', 'Charlie-Dan']})\n",
    "\n",
    "# Split 'Names' column on '-' and expand into separate columns\n",
    "df_split_expanded = df_split['Names'].str.split('-', expand=True)\n",
    "print(df_split_expanded)\n",
    "# Output: DataFrame with split elements in separate columns.\n",
    "#         0       1\n",
    "# 0   Alice     Bob\n",
    "# 1 Charlie     Dan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17. Removing Leading and Trailing Whitespace (`.str.strip()`)\n",
    "# Parameters: None (operates on a Series of string data)\n",
    "\n",
    "# Sample DataFrame with leading and trailing whitespace\n",
    "df_whitespace = pd.DataFrame({'Name': [' Alice ', 'Bob ', ' Charlie']})\n",
    "\n",
    "# Strip leading and trailing whitespace\n",
    "df_whitespace['Name'] = df_whitespace['Name'].str.strip()\n",
    "print(df_whitespace)\n",
    "# Output: DataFrame with whitespace removed.\n",
    "#       Name\n",
    "# 0    Alice\n",
    "# 1      Bob\n",
    "# 2  Charlie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 18. Changing a Column's Data Type to Category (`.astype('category')`)\n",
    "# Parameters:\n",
    "# dtype (str, dtype, or dict): Type to cast each column to (e.g., 'category').\n",
    "\n",
    "# Sample DataFrame with string data that can be categorized\n",
    "df_category = pd.DataFrame({'City': ['New York', 'Los Angeles', 'Chicago']})\n",
    "\n",
    "# Convert 'City' column to categorical type\n",
    "df_category['City'] = df_category['City'].astype('category')\n",
    "print(df_category.dtypes)\n",
    "# Output: DataFrame with 'City' column as a categorical type.\n",
    "# City    category\n",
    "# dtype: object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 19. Binning Numerical Data (`pd.cut()`)\n",
    "# Parameters:\n",
    "# x (array-like): Data to bin.\n",
    "# bins (int, sequence of scalars, or IntervalIndex): Number of bins or specific bin edges.\n",
    "# labels (array or bool, optional): Labels for the bins. If False, returns bin codes.\n",
    "\n",
    "# Sample DataFrame with numeric data\n",
    "df_numeric = pd.DataFrame({'Score': [15, 25, 35, 45, 55]})\n",
    "\n",
    "# Bin 'Score' column into three bins\n",
    "df_binned = pd.cut(df_numeric['Score'], bins=3, labels=['Low', 'Medium', 'High'])\n",
    "df_numeric['Category'] = df_binned\n",
    "print(df_numeric)\n",
    "# Output: DataFrame with 'Score' column binned into categories.\n",
    "#    Score Category\n",
    "# 0     15      Low\n",
    "# 1     25      Low\n",
    "# 2     35   Medium\n",
    "# 3     45   Medium\n",
    "# 4     55     High"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20. Dropping Columns (`.drop()`)\n",
    "# Parameters:\n",
    "# labels (str or list): Index or column labels to drop.\n",
    "# axis (int, optional): 0 for rows, 1 for columns. Default is 0.\n",
    "# inplace (bool, optional): If True, modifies the DataFrame in place. Default is False.\n",
    "\n",
    "# Drop a column from the DataFrame\n",
    "df_dropped_column = df_numeric.drop(columns=['Category'])\n",
    "print(df_dropped_column)\n",
    "# Output: DataFrame with 'Category' column removed.\n",
    "#    Score\n",
    "# 0     15\n",
    "# 1     25\n",
    "# 2     35\n",
    "# 3     45\n",
    "# 4     55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 21. Filling Missing Values with Specific Values (`.fillna()`)\n",
    "# Parameters:\n",
    "# value (scalar, dict, Series, or DataFrame): Value(s) to replace NaNs with.\n",
    "# method (str, optional): Fill method ('ffill' for forward, 'bfill' for backward).\n",
    "# inplace (bool, optional): If True, modifies the DataFrame in place. Default is False.\n",
    "\n",
    "# Sample DataFrame with missing values\n",
    "df_missing = pd.DataFrame({'A': [1, None, 3], 'B': [4, 5, None]})\n",
    "\n",
    "# Fill missing values with a specific value\n",
    "df_filled = df_missing.fillna(value=0)\n",
    "print(df_filled)\n",
    "# Output: DataFrame with missing values filled with 0.\n",
    "#     A    B\n",
    "# 0  1.0  4.0\n",
    "# 1  0.0  5.0\n",
    "# 2  3.0  0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 22. Dropping Rows Based on Condition (`.drop()` with `.index[]`)\n",
    "# Parameters:\n",
    "# labels (str or list): Index or column labels to drop.\n",
    "# axis (int, optional): 0 for rows, 1 for columns. Default is 0.\n",
    "# inplace (bool, optional): If True, modifies the DataFrame in place. Default is False.\n",
    "\n",
    "# Drop rows where 'A' column is less than 2\n",
    "df_dropped_rows = df_missing.drop(df_missing[df_missing['A'] < 2].index)\n",
    "print(df_dropped_rows)\n",
    "# Output: DataFrame with rows dropped based on a condition.\n",
    "#     A    B\n",
    "# 0  1.0  4.0\n",
    "# 2  3.0  NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 23. Creating Bins with Labels (`pd.cut()`)\n",
    "# Parameters:\n",
    "# x (array-like): Data to bin.\n",
    "# bins (int, sequence of scalars, or IntervalIndex): Number of bins or specific bin edges.\n",
    "# labels (array or bool, optional): Labels for the bins. If False, returns bin codes.\n",
    "# right (bool, optional): Indicates whether bins include the right edge. Default is True.\n",
    "\n",
    "# Sample DataFrame with numerical data\n",
    "df_scores = pd.DataFrame({'Score': [10, 20, 30, 40, 50, 60, 70, 80, 90]})\n",
    "\n",
    "# Create labeled bins for 'Score' column\n",
    "df_scores['Category'] = pd.cut(df_scores['Score'], bins=[0, 30, 60, 100], labels=['Low', 'Medium', 'High'])\n",
    "print(df_scores)\n",
    "# Output: DataFrame with scores categorized into 'Low', 'Medium', 'High' based on bins.\n",
    "#    Score Category\n",
    "# 0     10     Low\n",
    "# 1     20     Low\n",
    "# 2     30     Low\n",
    "# 3     40  Medium\n",
    "# 4     50  Medium\n",
    "# 5     60  Medium\n",
    "# 6     70    High\n",
    "# 7     80    High\n",
    "# 8     90    High"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 24. Converting Numeric Bins into Bin Codes (`pd.cut()` with `labels=False`)\n",
    "# Parameters:\n",
    "# x (array-like): Data to bin.\n",
    "# bins (int, sequence of scalars, or IntervalIndex): Number of bins or specific bin edges.\n",
    "# labels (array or bool, optional): If False, returns bin codes instead of labels.\n",
    "\n",
    "# Bin 'Score' into integer codes instead of labels\n",
    "df_scores['Category_Code'] = pd.cut(df_scores['Score'], bins=[0, 30, 60, 100], labels=False)\n",
    "print(df_scores)\n",
    "# Output: DataFrame with 'Score' column categorized into integer codes (0, 1, 2).\n",
    "#    Score Category  Category_Code\n",
    "# 0     10     Low              0\n",
    "# 1     20     Low              0\n",
    "# 2     30     Low              0\n",
    "# 3     40  Medium              1\n",
    "# 4     50  Medium              1\n",
    "# 5     60  Medium              1\n",
    "# 6     70    High              2\n",
    "# 7     80    High              2\n",
    "# 8     90    High              2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 25. Mapping Values to a New Scale (`.map()`)\n",
    "# Parameters:\n",
    "# arg (dict, Series, or function): Mapping correspondence or function.\n",
    "\n",
    "# Map 'Category' values to numerical scores\n",
    "category_mapping = {'Low': 1, 'Medium': 2, 'High': 3}\n",
    "df_scores['Category_Score'] = df_scores['Category'].map(category_mapping)\n",
    "print(df_scores)\n",
    "# Output: DataFrame with 'Category' mapped to scores (Low = 1, Medium = 2, High = 3).\n",
    "#    Score Category  Category_Code  Category_Score\n",
    "# 0     10     Low              0               1\n",
    "# 1     20     Low              0               1\n",
    "# 2     30     Low              0               1\n",
    "# 3     40  Medium              1               2\n",
    "# 4     50  Medium              1               2\n",
    "# 5     60  Medium              1               2\n",
    "# 6     70    High              2               3\n",
    "# 7     80    High              2               3\n",
    "# 8     90    High              2               3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 26. Checking for Missing Values (`.isnull()`)\n",
    "# Parameters: None\n",
    "\n",
    "# Check for missing values in the DataFrame\n",
    "missing_values = df_missing.isnull()\n",
    "print(missing_values)\n",
    "# Output: DataFrame with boolean values indicating missing (True) or non-missing (False) values.\n",
    "#        A      B\n",
    "# 0  False  False\n",
    "# 1   True  False\n",
    "# 2  False   True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 27. Counting Missing Values (`.isnull().sum()`)\n",
    "# Parameters: None\n",
    "\n",
    "# Count missing values in each column\n",
    "missing_counts = df_missing.isnull().sum()\n",
    "print(missing_counts)\n",
    "# Output: Series with count of missing values per column.\n",
    "# A    1\n",
    "# B    1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 28. Renaming Index (`.rename_axis()`)\n",
    "# Parameters:\n",
    "# mapper (str, optional): New name for the axis.\n",
    "# axis (int or str, optional): Axis to rename ('index' or 'columns'). Default is 'index'.\n",
    "\n",
    "# Rename the index in the DataFrame\n",
    "df_renamed_index = df_missing.rename_axis('Row ID').reset_index()\n",
    "print(df_renamed_index)\n",
    "# Output: DataFrame with the index renamed as 'Row ID'.\n",
    "#    Row ID    A    B\n",
    "# 0       0  1.0  4.0\n",
    "# 1       1  NaN  5.0\n",
    "# 2       2  3.0  NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 29. Assigning New Columns (`.assign()`)\n",
    "# Parameters:\n",
    "# **kwargs: New column names and values to assign (e.g., column='value').\n",
    "\n",
    "# Assign a new column based on a calculation\n",
    "df_assigned = df_scores.assign(Scaled_Score=lambda x: x['Score'] * 10)\n",
    "print(df_assigned)\n",
    "# Output: DataFrame with new column 'Scaled_Score' added as 10x 'Score' values.\n",
    "#    Score Category  Category_Code  Category_Score  Scaled_Score\n",
    "# 0     10     Low              0               1           100\n",
    "# 1     20     Low              0               1           200\n",
    "# 2     30     Low              0               1           300\n",
    "# 3     40  Medium              1               2           400\n",
    "# 4     50  Medium              1               2           500\n",
    "# 5     60  Medium              1               2           600\n",
    "# 6     70    High              2               3           700\n",
    "# 7     80    High              2               3           800\n",
    "# 8     90    High              2               3           900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30. Dropping Rows with All Missing Values (`.dropna(how='all')`)\n",
    "# Parameters:\n",
    "# axis (int, optional): Axis along which to drop rows or columns (0 for rows, 1 for columns). Default is 0.\n",
    "# how (str, optional): 'any' to drop if any NA values present, 'all' to drop only if all values are NA.\n",
    "# inplace (bool, optional): If True, modifies the DataFrame in place. Default is False.\n",
    "\n",
    "# Drop rows where all values are missing\n",
    "df_all_na = pd.DataFrame({'A': [None, None, 3], 'B': [None, 5, None]})\n",
    "df_dropped_all_na = df_all_na.dropna(how='all')\n",
    "print(df_dropped_all_na)\n",
    "# Output: DataFrame with rows dropped where all values are NaN.\n",
    "#     A    B"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
